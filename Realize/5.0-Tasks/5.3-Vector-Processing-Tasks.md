# Tasks: Vector Processing & Embedding

**Input**: Specification 4.6-Citadel-Vector-Processing.md, Technology Stack v3.2
**Prerequisites**: Data acquisition agents complete, Qdrant configured

## Execution Flow (main)
```
1. Load vector processing specification
   → Extract: chunking strategies, embedding requirements, storage patterns
2. Load technology stack for dependencies
   → Sentence Transformers 3.2.x, Qdrant client 1.12.x, transformers 4.46.x
3. Generate tasks by category:
   → Setup: embedding models, Qdrant connection
   → Tests: chunking tests, embedding tests, storage tests (TDD)
   → Core: content chunking, embedding generation, vector storage
   → Integration: indexing service, batch processing
4. Apply task rules:
   → Different chunking strategies = mark [P] for parallel
   → Tests before implementation (TDD)
5. Number tasks sequentially (T129...)
6. Return: SUCCESS (vector processing ready)
```

## Format: `[ID] [P?] Description`
- **[P]**: Can run in parallel (different files, no dependencies)
- Include exact file paths in backend/src/agents/processing/ and backend/src/services/

## Phase 3.1: Setup & Model Configuration
- [ ] T129 Install Sentence Transformers 3.2.x and dependencies
- [ ] T130 Download all-MiniLM-L6-v2 model (384 dimensions)
- [ ] T131 Download all-mpnet-base-v2 model (768 dimensions)
- [ ] T132 Download multilingual-e5-large model (multi-language)
- [ ] T133 Configure Qdrant client connection to cluster
- [ ] T134 Create vector collection schemas with metadata

## Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3
**CRITICAL: These tests MUST be written and MUST FAIL before ANY implementation**

### Content Chunking Tests
- [ ] T135 [P] Contract test MarkdownChunker in backend/tests/contract/test_markdown_chunker.py
- [ ] T136 [P] Contract test HierarchicalChunker in backend/tests/contract/test_hierarchical_chunker.py
- [ ] T137 [P] Contract test SemanticChunker in backend/tests/contract/test_semantic_chunker.py
- [ ] T138 Integration test chunking strategies in backend/tests/integration/test_chunking.py

### Embedding Generation Tests
- [ ] T139 [P] Contract test EmbeddingGenerator in backend/tests/contract/test_embedding_generator.py
- [ ] T140 [P] Contract test BatchEmbedder in backend/tests/contract/test_batch_embedder.py
- [ ] T141 Integration test embedding pipeline in backend/tests/integration/test_embedding_pipeline.py

### Vector Storage Tests
- [ ] T142 [P] Contract test VectorStorage in backend/tests/contract/test_vector_storage.py
- [ ] T143 Integration test Qdrant operations in backend/tests/integration/test_qdrant_operations.py
- [ ] T144 Integration test complete indexing flow in backend/tests/integration/test_indexing_flow.py

## Phase 3.3: Content Chunking Implementation (ONLY after tests are failing)

### Chunking Agents
- [ ] T145 [P] Implement MarkdownChunker in backend/src/agents/processing/markdown_chunker.py
- [ ] T146 [P] Implement HierarchicalChunker in backend/src/agents/processing/hierarchical_chunker.py
- [ ] T147 [P] Implement SemanticChunker in backend/src/agents/processing/semantic_chunker.py
- [ ] T148 Implement ChunkingStrategy selector in backend/src/agents/processing/chunking_strategy.py

### Chunking Utilities
- [ ] T149 [P] Implement header detection in backend/src/agents/utils/header_parser.py
- [ ] T150 [P] Implement semantic boundary detection in backend/src/agents/utils/boundary_detector.py
- [ ] T151 [P] Implement chunk size optimization in backend/src/agents/utils/chunk_optimizer.py
- [ ] T152 Implement chunk metadata extractor in backend/src/agents/utils/chunk_metadata.py

## Phase 3.4: Embedding Generation
- [ ] T153 Implement EmbeddingGenerator in backend/src/agents/processing/embedding_generator.py
- [ ] T154 Implement model selection logic (based on content type/language)
- [ ] T155 Implement batch embedding for efficiency
- [ ] T156 Implement embedding caching for repeated content
- [ ] T157 Implement embedding quality validation
- [ ] T158 Performance test: Generate 1000 embeddings in <10 seconds

## Phase 3.5: Vector Storage Layer
- [ ] T159 Implement VectorStorage interface in backend/src/services/vector_storage.py
- [ ] T160 Implement Qdrant operations wrapper
- [ ] T161 Implement batch insert optimization
- [ ] T162 Implement metadata indexing for filtering
- [ ] T163 Implement vector upsert logic for updates
- [ ] T164 Implement collection management (create, delete, list)

## Phase 3.6: Indexing Service
- [ ] T165 Create IndexingService in backend/src/services/indexing_service.py
- [ ] T166 Implement content reception from acquisition service
- [ ] T167 Implement chunking orchestration
- [ ] T168 Implement embedding generation orchestration
- [ ] T169 Implement vector storage orchestration
- [ ] T170 Implement progress tracking with event emission
- [ ] T171 Implement failure handling and retry logic

## Phase 3.7: Metadata Management
- [ ] T172 Implement DocumentMetadata model in backend/src/models/document_metadata.py
- [ ] T173 Implement ChunkMetadata model in backend/src/models/chunk_metadata.py
- [ ] T174 Implement provenance tracking in metadata
- [ ] T175 Implement metadata indexing for fast filtering
- [ ] T176 Implement metadata validation

## Phase 3.8: Batch Processing & Optimization
- [ ] T177 Implement batch processor for large document collections
- [ ] T178 Implement memory management for large batches
- [ ] T179 Implement parallel processing for independent documents
- [ ] T180 Implement streaming processing for very large files
- [ ] T181 Performance test: Process 10,000 documents in <30 minutes

## Phase 3.9: Quality Metrics & Validation
- [ ] T182 Implement chunk quality scoring in backend/src/agents/processing/quality_scorer.py
- [ ] T183 Implement embedding quality validation
- [ ] T184 Implement vector storage integrity checks
- [ ] T185 Implement processing analytics and metrics
- [ ] T186 Create quality reports dashboard

## Phase 3.10: API Endpoints
- [ ] T187 POST /api/v1/index endpoint in backend/src/api/v1/indexing.py
- [ ] T188 GET /api/v1/index/{job_id}/status endpoint
- [ ] T189 GET /api/v1/collections/{collection_id}/stats endpoint
- [ ] T190 POST /api/v1/collections/{collection_id}/reindex endpoint
- [ ] T191 DELETE /api/v1/collections/{collection_id}/documents endpoint

## Phase 3.11: Documentation & Polish
- [ ] T192 [P] Document chunking strategies in backend/docs/processing/chunking.md
- [ ] T193 [P] Document embedding models in backend/docs/processing/embeddings.md
- [ ] T194 [P] Create processing examples in backend/examples/processing/
- [ ] T195 [P] Update API documentation with OpenAPI specs
- [ ] T196 Run manual testing scenarios from specification
- [ ] T197 Code review and refactoring for performance

## Dependencies
```
Setup (T129-T134) → Tests (T135-T144)
Tests (T135-T144) → Chunking Implementation (T145-T152)
Chunking → Embedding Generation (T153-T158)
Embedding Generation → Vector Storage (T159-T164)
Vector Storage → Indexing Service (T165-T171)
Indexing Service → Metadata Management (T172-T176)
Metadata → Batch Processing (T177-T181)
Batch Processing → Quality Metrics (T182-T186)
Indexing Service → API Endpoints (T187-T191)
All Implementation → Documentation (T192-T197)
```

## Parallel Execution Examples
```
# Chunking Tests Phase (T135-T137):
Task T135: Contract test MarkdownChunker
Task T136: Contract test HierarchicalChunker
Task T137: Contract test SemanticChunker

# Chunking Implementation Phase (T145-T147):
Task T145: Implement MarkdownChunker
Task T146: Implement HierarchicalChunker
Task T147: Implement SemanticChunker

# Chunking Utilities Phase (T149-T151):
Task T149: Implement header detection
Task T150: Implement semantic boundary detection
Task T151: Implement chunk size optimization
```

## Processing Strategy Notes

### Markdown Chunking
- Split on header hierarchy (H1, H2, H3...)
- Maintain context with parent headers
- Target chunk size: 512 tokens
- Preserve code blocks and lists

### Hierarchical Chunking
- Multi-level document structure
- Parent-child chunk relationships
- Configurable depth levels
- Context preservation across levels

### Semantic Chunking
- NLP-based boundary detection
- Topic coherence scoring
- Adaptive chunk sizing
- Language-aware processing

### Embedding Models

**all-MiniLM-L6-v2:**
- Use for: Fast, general-purpose embedding
- Dimensions: 384
- Speed: ~1ms per chunk
- Best for: Real-time indexing

**all-mpnet-base-v2:**
- Use for: High-quality embedding
- Dimensions: 768
- Speed: ~3ms per chunk
- Best for: Critical content

**multilingual-e5-large:**
- Use for: Multi-language content
- Dimensions: 1024
- Speed: ~5ms per chunk
- Best for: International content

## Validation Checklist
- [x] All chunking strategies have tests
- [x] All embedding operations have tests
- [x] Tests before implementation (TDD)
- [x] Parallel tasks truly independent
- [x] Performance targets defined (1000 chunks in <10s)
- [x] Quality metrics implemented
- [x] Metadata properly tracked
- [x] API endpoints properly defined

---

**Status:** Vector Processing & Embedding - Ready for Implementation  
**Next Phase:** Retrieval & Query Processing (Phase 4)

